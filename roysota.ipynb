{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U torch torchvision nobuco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import nobuco\n",
    "from nobuco import ChannelOrder, ChannelOrderingStrategy\n",
    "from nobuco.layers.weight import WeightLayer\n",
    "\n",
    "@nobuco.converter(torch.split, channel_ordering_strategy=ChannelOrderingStrategy.MINIMUM_TRANSPOSITIONS)\n",
    "def split(input, split_size_or_sections, dim=0):\n",
    "    def split_fn(input, split_size_or_sections, dim=0):\n",
    "        if isinstance(split_size_or_sections, int):\n",
    "            return tf.split(input, num_or_size_splits=split_size_or_sections, axis=dim)\n",
    "        else:\n",
    "            return tf.split(input, num_or_size_splits=split_size_or_sections.tolist(), axis=dim)\n",
    "    return split_fn\n",
    "\n",
    "# FORCE_PYTORCH_ORDER -> orange imprecise\n",
    "# FORCE_TENSORFLOW_ORDER -> not work\n",
    "# MINIMUM_TRANSPOSITIONS -> kinda work (not really)\n",
    "@nobuco.converter(F.affine_grid, channel_ordering_strategy=ChannelOrderingStrategy.FORCE_PYTORCH_ORDER)\n",
    "def affine_grid(theta, size, align_corners=None):\n",
    "    def affine_grid_fn(theta, size):\n",
    "        # Estraiamo la dimensione della griglia\n",
    "        _, _, height, width  = size\n",
    "\n",
    "        # Creiamo una griglia di coordinate normalizzate\n",
    "        x = tf.linspace(-1.0, 1.0, width)\n",
    "        y = tf.linspace(-1.0, 1.0, height)\n",
    "        x_t, y_t = tf.meshgrid(x, y)\n",
    "        ones = tf.ones_like(x_t)\n",
    "        grid = tf.stack([x_t, y_t, ones], axis=-1)\n",
    "\n",
    "        # Riformattiamo la griglia per poter fare una moltiplicazione batch-wise\n",
    "        grid = tf.reshape(grid, [-1, height * width, 3])\n",
    "\n",
    "        # Applichiamo la trasformazione affine\n",
    "        theta = tf.reshape(theta, [-1, 2, 3])\n",
    "        grid = tf.matmul(grid, tf.transpose(theta, [0, 2, 1]))\n",
    "        \n",
    "        # Riportiamo la griglia nella sua forma originale\n",
    "        grid = tf.reshape(grid, [-1, height, width, 2])\n",
    "\n",
    "        return grid\n",
    "    return affine_grid_fn\n",
    "\n",
    "\n",
    "@nobuco.converter(F.grid_sample, channel_ordering_strategy=ChannelOrderingStrategy.FORCE_TENSORFLOW_ORDER)\n",
    "# def converter_grid_sample(input: Tensor, grid: Tensor, mode: str = \"bilinear\", padding_mode: str = \"zeros\", align_corners: Optional[bool] = None):\n",
    "def converter_grid_sample(input, grid):\n",
    "    def grid_sample(input, grid):\n",
    "        def process_coord(grid, w_h):\n",
    "            pixs = (grid + 1) * (0.5 * w_h) - 0.5\n",
    "            pixs = tf.clip_by_value(pixs, -1, w_h) + 1\n",
    "            return pixs\n",
    "        \n",
    "        def gather(input, y, x, b, h, w, c):\n",
    "            w_padded = w + 2\n",
    "            h_padded = h + 2\n",
    "            linear_coordinates = tf.cast(y * w_padded + x, dtype=tf.int32)\n",
    "\n",
    "            #print(linear_coordinates.shape)\n",
    "\n",
    "            # linear_coordinates = tf.reshape(linear_coordinates, shape=(b, h, w))\n",
    "            linear_coordinates = tf.reshape(linear_coordinates, shape=(b, h/2, w/2))\n",
    "            input = tf.reshape(input, shape=(b, h_padded * w_padded, c))\n",
    "            out = tf.gather(params=input, indices=linear_coordinates, batch_dims=1)\n",
    "            return out\n",
    "\n",
    "        grid = tf.transpose(grid, perm=(0, 3, 1, 2))\n",
    "        b, h, w, c = tf.cast(tf.shape(input), tf.float32)\n",
    "        # b, c, h, w = tf.cast(tf.shape(input), tf.float32)\n",
    "        \n",
    "        #print(tf.shape(input))\n",
    "\n",
    "        grid_x, grid_y = tf.split(grid, num_or_size_splits=2, axis=-1)\n",
    "        \n",
    "        x = process_coord(grid_x, w)\n",
    "        y = process_coord(grid_y, h)\n",
    "\n",
    "        input = tf.keras.layers.ZeroPadding2D(padding=(1, 1))(input)\n",
    "\n",
    "        x0 = tf.math.floor(x)\n",
    "        y0 = tf.math.floor(y)\n",
    "        x1 = tf.math.ceil(x)\n",
    "        y1 = tf.math.ceil(y)\n",
    "\n",
    "        dx = x - x0\n",
    "        dy = y - y0\n",
    "        oneminus_dx = 1 - dx\n",
    "        oneminus_dy = 1 - dy\n",
    "        w_y0_x0 = oneminus_dy * oneminus_dx\n",
    "        w_y1_x0 = dy * oneminus_dx\n",
    "        w_y1_x1 = dy * dx\n",
    "        w_y0_x1 = oneminus_dy * dx\n",
    "\n",
    "        v_y0_x0 = gather(input, y0, x0, b, h, w, c)\n",
    "        v_y1_x0 = gather(input, y1, x0, b, h, w, c)\n",
    "        v_y1_x1 = gather(input, y1, x1, b, h, w, c)\n",
    "        v_y0_x1 = gather(input, y0, x1, b, h, w, c)\n",
    "\n",
    "        return w_y0_x0 * v_y0_x0 + w_y1_x0 * v_y1_x0 + w_y1_x1 * v_y1_x1 + w_y0_x1 * v_y0_x1\n",
    "\n",
    "    return grid_sample\n",
    "\n",
    "class CNNConStn(nn.Module):\n",
    "    def __init__(self, img_size, nclasses, fixed_scale=True):\n",
    "        super(CNNConStn, self).__init__()\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.fixed_scale = fixed_scale\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),  # 48 corresponds to the number of input features it\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # IN remains unchanged during any pooling operation\n",
    "            #nn.Dropout(p=0.3)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            #nn.Dropout(p=0.3)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            #nn.Dropout(p=0.3)\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            #nn.Dropout(p=0.3)\n",
    "        )\n",
    "\n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.3)\n",
    "        )\n",
    "\n",
    "        self.block6 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.AvgPool2d(kernel_size=4)  # paper: 8\n",
    "        )\n",
    "\n",
    "        self.block1_stn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),  # 48 corresponds to the number of input features it\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # IN remains unchanged during any pooling operation\n",
    "            #nn.Dropout(p=0.3)\n",
    "        )\n",
    "\n",
    "        self.block2_stn = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            #nn.Dropout(p=0.3)\n",
    "        )\n",
    "\n",
    "        self.block3_stn = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            #nn.Dropout(p=0.3)\n",
    "        )\n",
    "\n",
    "        self.block4_stn = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            #nn.Dropout(p=0.3)\n",
    "        )\n",
    "\n",
    "        self.block5_stn = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.3)\n",
    "        )\n",
    "\n",
    "        self.block6_stn = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.block7 = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(256, nclasses)\n",
    "\n",
    "        if fixed_scale: # scaling is kept fixed, only translation is learned\n",
    "            # Regressor for the 3 * 2 affine matrix\n",
    "            self.fc_loc = nn.Sequential(\n",
    "                nn.Linear(128 * 7 * 7, 32),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(32, 4)  # predict just translation params\n",
    "            )\n",
    "            # weight_layer (?)\n",
    "            self.fc_loc[2].weight.data.zero_()\n",
    "            self.fc_loc[2].bias.data.copy_(torch.tensor([0.3, 0.3, 0.2, 0.2], dtype=torch.float))\n",
    "        else: # scaling, rotation and translation are learned\n",
    "            # Regressor for the 3 * 2 affine matrix\n",
    "            self.fc_loc = nn.Sequential(\n",
    "                nn.Linear(128 * 7 * 7, 32),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "            self.trans = nn.Linear(32, 4)  # predict translation params\n",
    "            self.scaling = nn.Linear(32, 2)  # predict the scaling parameter\n",
    "            self.rotation = nn.Linear(32, 4)  # predict the rotation parameters\n",
    "\n",
    "            # weight_layer (?)\n",
    "            # Initialize the weights/bias with some priors\n",
    "            self.trans.weight.data.zero_()\n",
    "            self.trans.bias.data.copy_(torch.tensor([0.3, 0.3, 0.2, 0.2], dtype=torch.float))\n",
    "\n",
    "            self.scaling.weight.data.zero_()\n",
    "            self.scaling.bias.data.copy_(torch.tensor([0.5, 0.75], dtype=torch.float))\n",
    "\n",
    "            self.rotation.weight.data.zero_()\n",
    "            self.rotation.bias.data.normal_(0, 0.1)\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        scaling = 0 # dummy variable for just translation\n",
    "        xs = self.block1_stn(x)\n",
    "        xs = self.block2_stn(xs)\n",
    "        xs = self.block3_stn(xs)\n",
    "        xs = self.block4_stn(xs)\n",
    "        xs = self.block5_stn(xs)\n",
    "        xs = self.block6_stn(xs)\n",
    "        xs = xs.view(-1, 128 * 7 * 7)\n",
    "        \n",
    "        if self.fixed_scale:\n",
    "            trans = self.fc_loc(xs)\n",
    "            bs = trans.shape[0]\n",
    "            trans_1, trans_2 = torch.split(trans, split_size_or_sections=trans.shape[1] // 2, dim=1)\n",
    "            # prepare theta for each resolution\n",
    "            theta_1 = torch.cat([(torch.eye(2, 2, device=x.device) * 0.5).view(1, 2, 2).repeat(bs, 1, 1),\n",
    "                                 trans_1.view(bs, 2, 1)], dim=2)\n",
    "            theta_2 = torch.cat([(torch.eye(2, 2, device=x.device) * 0.75).view(1, 2, 2).repeat(bs, 1, 1),\n",
    "                                 trans_1.view(bs, 2, 1)], dim=2)\n",
    "        else:\n",
    "            xs = self.fc_loc(xs)\n",
    "            # predict the scaling params\n",
    "            scaling = F.sigmoid(self.scaling(xs))\n",
    "            scaling_1, scaling_2 = torch.split(scaling, split_size_or_sections=scaling.shape[1] // 2, dim=1)\n",
    "            # predict the translation params\n",
    "            trans = self.trans(xs)\n",
    "            bs = trans.shape[0]\n",
    "            trans_1, trans_2 = torch.split(trans, split_size_or_sections=trans.shape[1] // 2, dim=1)\n",
    "            # predict the rotation params\n",
    "            rot = self.rotation(xs)\n",
    "            rot_1, rot_2 = torch.split(rot, split_size_or_sections=rot.shape[1] // 2, dim=1)\n",
    "            # prepare theta for each resolution\n",
    "            rot_1 = torch.ones(2, 2, device=x.device).fill_diagonal_(0).view(1, 2, 2).repeat(bs, 1, 1) * rot_1.view(bs, 2,\n",
    "                                                                                                                  1)\n",
    "            rot_2 = torch.ones(2, 2, device=x.device).fill_diagonal_(0).view(1, 2, 2).repeat(bs, 1, 1) * rot_2.view(bs, 2,\n",
    "                                                                                                                  1)\n",
    "            # add to the scaling params\n",
    "            rot_1 = rot_1 + torch.eye(2, 2, device=x.device).view(1, 2, 2) * scaling_1.view(bs, 1, 1)\n",
    "            rot_2 = rot_2 + torch.eye(2, 2, device=x.device).view(1, 2, 2) * scaling_2.view(bs, 1, 1)\n",
    "            # prepare the final theta\n",
    "            theta_1 = torch.cat([rot_1, trans_1.view(bs, 2, 1)], dim=2)\n",
    "            theta_2 = torch.cat([rot_2, trans_1.view(bs, 2, 1)], dim=2)\n",
    "        \n",
    "        # get the shapes\n",
    "        bs, c, _ , _ = x.size()\n",
    "        h , w = self.img_size // 2, self.img_size // 2\n",
    "        stn_out_size = (bs, c, h, w)\n",
    "        \n",
    "        # apply transformations\n",
    "        grid_1 = F.affine_grid(theta_1, stn_out_size)\n",
    "        grid_2 = F.affine_grid(theta_2, stn_out_size)\n",
    "\n",
    "        x_1 = F.grid_sample(x, grid_1)\n",
    "        x_2 = F.grid_sample(x, grid_2)\n",
    "\n",
    "        x = torch.cat([x_1, x_2], dim=0)\n",
    "\n",
    "        return x, scaling\n",
    "\n",
    "    def forward(self, x, domains=None):\n",
    "        x, scaling = self.stn(x)  # transform the input\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = F.avg_pool2d(x, x.shape[-2])\n",
    "        x = x.view(x.shape[0], -1)  # reshape the tensor\n",
    "        x = F.dropout(self.block7(x), training=self.training)\n",
    "        x = self.out(x)\n",
    "        return x, scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_image = torch.rand(size=(1, 3, 224, 224))\n",
    "pytorch_module = CNNConStn(224, 4, True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edoardoconti/Tesi/us-ordinal-classification/.venv/lib/python3.11/site-packages/torch/nn/functional.py:4377: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/Users/edoardoconti/Tesi/us-ordinal-classification/.venv/lib/python3.11/site-packages/torch/nn/functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/Users/edoardoconti/Tesi/us-ordinal-classification/.venv/lib/python3.11/site-packages/nobuco/converters/validation.py:55: RuntimeWarning: [<function affine_grid at 0x1307b8c20>|CNNConStn] conversion procedure might be incorrect: max. discrepancy for output #0 is 0.00446 (0.561%)\n",
      "  warnings.warn(warn_string, category=RuntimeWarning)\n",
      "/Users/edoardoconti/Tesi/us-ordinal-classification/.venv/lib/python3.11/site-packages/nobuco/converters/validation.py:55: RuntimeWarning: [<function affine_grid at 0x1307b8c20>|CNNConStn] conversion procedure might be incorrect: max. discrepancy for output #0 is 0.00670 (1.511%)\n",
      "  warnings.warn(warn_string, category=RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend:\n",
      "    \u001b[32mGreen\u001b[0m — conversion successful\n",
      "    \u001b[33mYellow\u001b[0m — conversion imprecise\n",
      "    \u001b[31mRed\u001b[0m — conversion failed\n",
      "    \u001b[31m\u001b[7mRed\u001b[0m — no converter found\n",
      "    \u001b[0m\u001b[1mBold\u001b[0m — conversion applied directly\n",
      "    * — subgraph reused\n",
      "    \u001b[7mTensor\u001b[0m — this output is not dependent on any of subgraph's input tensors\n",
      "    \u001b[4mTensor\u001b[0m — this input is a parameter / constant\n",
      "    \u001b[90mTensor\u001b[0m — this tensor is useless\n",
      "\n",
      "\u001b[32mCNNConStn[__main__]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> (float32_241<2,4>\u001b[0m, 0)\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_17<1,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_3<1,32,224,224>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_0<1,3,224,224>\u001b[0m, float32_1<32,3,3,3>\u001b[0m, float32_2<32>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_3<1,32,224,224>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_3<1,32,224,224>\u001b[0m) -> float32_8<1,32,224,224>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_3<1,32,224,224>\u001b[0m, float32_4<32>\u001b[0m, float32_5<32>\u001b[0m, float32_6<32>\u001b[0m, float32_7<32>\u001b[0m, False, 0.1, 1e-05) -> float32_8<1,32,224,224>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_8<1,32,224,224>\u001b[0m) -> float32_8<1,32,224,224>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_8<1,32,224,224>\u001b[0m, inplace=True) -> float32_8<1,32,224,224>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_8<1,32,224,224>\u001b[0m) -> float32_11<1,32,224,224>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_8<1,32,224,224>\u001b[0m, float32_9<32,32,3,3>\u001b[0m, float32_10<32>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_11<1,32,224,224>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_11<1,32,224,224>\u001b[0m) -> float32_16<1,32,224,224>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_11<1,32,224,224>\u001b[0m, float32_12<32>\u001b[0m, float32_13<32>\u001b[0m, float32_14<32>\u001b[0m, float32_15<32>\u001b[0m, False, 0.1, 1e-05) -> float32_16<1,32,224,224>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_16<1,32,224,224>\u001b[0m) -> float32_16<1,32,224,224>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_16<1,32,224,224>\u001b[0m, inplace=True) -> float32_16<1,32,224,224>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_16<1,32,224,224>\u001b[0m) -> float32_17<1,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_16<1,32,224,224>\u001b[0m, 2, 2, 0, 1, ceil_mode=False, return_indices=False) -> float32_17<1,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_17<1,32,112,112>\u001b[0m) -> float32_34<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_17<1,32,112,112>\u001b[0m) -> float32_20<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_17<1,32,112,112>\u001b[0m, float32_18<64,32,3,3>\u001b[0m, float32_19<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_20<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_20<1,64,112,112>\u001b[0m) -> float32_25<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_20<1,64,112,112>\u001b[0m, float32_21<64>\u001b[0m, float32_22<64>\u001b[0m, float32_23<64>\u001b[0m, float32_24<64>\u001b[0m, False, 0.1, 1e-05) -> float32_25<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_25<1,64,112,112>\u001b[0m) -> float32_25<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_25<1,64,112,112>\u001b[0m, inplace=True) -> float32_25<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_25<1,64,112,112>\u001b[0m) -> float32_28<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_25<1,64,112,112>\u001b[0m, float32_26<64,64,3,3>\u001b[0m, float32_27<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_28<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_28<1,64,112,112>\u001b[0m) -> float32_33<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_28<1,64,112,112>\u001b[0m, float32_29<64>\u001b[0m, float32_30<64>\u001b[0m, float32_31<64>\u001b[0m, float32_32<64>\u001b[0m, False, 0.1, 1e-05) -> float32_33<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_33<1,64,112,112>\u001b[0m) -> float32_33<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_33<1,64,112,112>\u001b[0m, inplace=True) -> float32_33<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_33<1,64,112,112>\u001b[0m) -> float32_34<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_33<1,64,112,112>\u001b[0m, 2, 2, 0, 1, ceil_mode=False, return_indices=False) -> float32_34<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_34<1,64,56,56>\u001b[0m) -> float32_51<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_34<1,64,56,56>\u001b[0m) -> float32_37<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_34<1,64,56,56>\u001b[0m, float32_35<64,64,3,3>\u001b[0m, float32_36<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_37<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_37<1,64,56,56>\u001b[0m) -> float32_42<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_37<1,64,56,56>\u001b[0m, float32_38<64>\u001b[0m, float32_39<64>\u001b[0m, float32_40<64>\u001b[0m, float32_41<64>\u001b[0m, False, 0.1, 1e-05) -> float32_42<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_42<1,64,56,56>\u001b[0m) -> float32_42<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_42<1,64,56,56>\u001b[0m, inplace=True) -> float32_42<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_42<1,64,56,56>\u001b[0m) -> float32_45<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_42<1,64,56,56>\u001b[0m, float32_43<64,64,3,3>\u001b[0m, float32_44<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_45<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_45<1,64,56,56>\u001b[0m) -> float32_50<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_45<1,64,56,56>\u001b[0m, float32_46<64>\u001b[0m, float32_47<64>\u001b[0m, float32_48<64>\u001b[0m, float32_49<64>\u001b[0m, False, 0.1, 1e-05) -> float32_50<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_50<1,64,56,56>\u001b[0m) -> float32_50<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_50<1,64,56,56>\u001b[0m, inplace=True) -> float32_50<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_50<1,64,56,56>\u001b[0m) -> float32_51<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_50<1,64,56,56>\u001b[0m, 2, 2, 0, 1, ceil_mode=False, return_indices=False) -> float32_51<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_51<1,64,28,28>\u001b[0m) -> float32_68<1,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_51<1,64,28,28>\u001b[0m) -> float32_54<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_51<1,64,28,28>\u001b[0m, float32_52<64,64,3,3>\u001b[0m, float32_53<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_54<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_54<1,64,28,28>\u001b[0m) -> float32_59<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_54<1,64,28,28>\u001b[0m, float32_55<64>\u001b[0m, float32_56<64>\u001b[0m, float32_57<64>\u001b[0m, float32_58<64>\u001b[0m, False, 0.1, 1e-05) -> float32_59<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_59<1,64,28,28>\u001b[0m) -> float32_59<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_59<1,64,28,28>\u001b[0m, inplace=True) -> float32_59<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_59<1,64,28,28>\u001b[0m) -> float32_62<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_59<1,64,28,28>\u001b[0m, float32_60<64,64,3,3>\u001b[0m, float32_61<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_62<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_62<1,64,28,28>\u001b[0m) -> float32_67<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_62<1,64,28,28>\u001b[0m, float32_63<64>\u001b[0m, float32_64<64>\u001b[0m, float32_65<64>\u001b[0m, float32_66<64>\u001b[0m, False, 0.1, 1e-05) -> float32_67<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_67<1,64,28,28>\u001b[0m) -> float32_67<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_67<1,64,28,28>\u001b[0m, inplace=True) -> float32_67<1,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_67<1,64,28,28>\u001b[0m) -> float32_68<1,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_67<1,64,28,28>\u001b[0m, 2, 2, 0, 1, ceil_mode=False, return_indices=False) -> float32_68<1,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_68<1,64,14,14>\u001b[0m) -> float32_85<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_68<1,64,14,14>\u001b[0m) -> float32_71<1,128,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_68<1,64,14,14>\u001b[0m, float32_69<128,64,3,3>\u001b[0m, float32_70<128>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_71<1,128,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_71<1,128,14,14>\u001b[0m) -> float32_76<1,128,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_71<1,128,14,14>\u001b[0m, float32_72<128>\u001b[0m, float32_73<128>\u001b[0m, float32_74<128>\u001b[0m, float32_75<128>\u001b[0m, False, 0.1, 1e-05) -> float32_76<1,128,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_76<1,128,14,14>\u001b[0m) -> float32_76<1,128,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_76<1,128,14,14>\u001b[0m, inplace=True) -> float32_76<1,128,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_76<1,128,14,14>\u001b[0m) -> float32_79<1,128,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_76<1,128,14,14>\u001b[0m, float32_77<128,128,3,3>\u001b[0m, float32_78<128>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_79<1,128,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_79<1,128,14,14>\u001b[0m) -> float32_84<1,128,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_79<1,128,14,14>\u001b[0m, float32_80<128>\u001b[0m, float32_81<128>\u001b[0m, float32_82<128>\u001b[0m, float32_83<128>\u001b[0m, False, 0.1, 1e-05) -> float32_84<1,128,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_84<1,128,14,14>\u001b[0m) -> float32_84<1,128,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_84<1,128,14,14>\u001b[0m, inplace=True) -> float32_84<1,128,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_84<1,128,14,14>\u001b[0m) -> float32_85<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_84<1,128,14,14>\u001b[0m, 2, 2, 0, 1, ceil_mode=False, return_indices=False) -> float32_85<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_85<1,128,7,7>\u001b[0m) -> float32_85<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_85<1,128,7,7>\u001b[0m, 0.3, False, False) -> float32_85<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_85<1,128,7,7>\u001b[0m) -> float32_101<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_85<1,128,7,7>\u001b[0m) -> float32_88<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_85<1,128,7,7>\u001b[0m, float32_86<128,128,3,3>\u001b[0m, float32_87<128>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_88<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_88<1,128,7,7>\u001b[0m) -> float32_93<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_88<1,128,7,7>\u001b[0m, float32_89<128>\u001b[0m, float32_90<128>\u001b[0m, float32_91<128>\u001b[0m, float32_92<128>\u001b[0m, False, 0.1, 1e-05) -> float32_93<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_93<1,128,7,7>\u001b[0m) -> float32_93<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_93<1,128,7,7>\u001b[0m, inplace=True) -> float32_93<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_93<1,128,7,7>\u001b[0m) -> float32_96<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_93<1,128,7,7>\u001b[0m, float32_94<128,128,3,3>\u001b[0m, float32_95<128>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_96<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_96<1,128,7,7>\u001b[0m) -> float32_101<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_96<1,128,7,7>\u001b[0m, float32_97<128>\u001b[0m, float32_98<128>\u001b[0m, float32_99<128>\u001b[0m, float32_100<128>\u001b[0m, False, 0.1, 1e-05) -> float32_101<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_101<1,128,7,7>\u001b[0m) -> float32_101<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_101<1,128,7,7>\u001b[0m, inplace=True) -> float32_101<1,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_101<1,128,7,7>\u001b[0m, -1, 6272) -> float32_102<1,6272>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_102<1,6272>\u001b[0m) -> float32_108<1,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_102<1,6272>\u001b[0m) -> float32_105<1,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_102<1,6272>\u001b[0m, float32_103<32,6272>\u001b[0m, float32_104<32>\u001b[0m) -> float32_105<1,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_105<1,32>\u001b[0m) -> float32_105<1,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_105<1,32>\u001b[0m, inplace=True) -> float32_105<1,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_105<1,32>\u001b[0m) -> float32_108<1,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_105<1,32>\u001b[0m, float32_106<4,32>\u001b[0m, float32_107<4>\u001b[0m) -> float32_108<1,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1msplit[torch]\u001b[0m(float32_108<1,4>\u001b[0m, split_size_or_sections=2, dim=1) -> (float32_109<1,2>\u001b[0m, \u001b[90mfloat32_110<1,2>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_111<2,2>\u001b[0m, 0.5) -> float32_112<2,2>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_112<2,2>\u001b[0m, 1, 2, 2) -> float32_113<1,2,2>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mrepeat[torch.Tensor]\u001b[0m(float32_113<1,2,2>\u001b[0m, 1, 1, 1) -> float32_114<1,2,2>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_109<1,2>\u001b[0m, 1, 2, 1) -> float32_115<1,2,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_114<1,2,2>\u001b[0m, float32_115<1,2,1>\u001b[0m], dim=2) -> float32_116<1,2,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_117<2,2>\u001b[0m, 0.75) -> float32_118<2,2>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_118<2,2>\u001b[0m, 1, 2, 2) -> float32_119<1,2,2>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mrepeat[torch.Tensor]\u001b[0m(float32_119<1,2,2>\u001b[0m, 1, 1, 1) -> float32_120<1,2,2>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_109<1,2>\u001b[0m, 1, 2, 1) -> float32_121<1,2,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_120<1,2,2>\u001b[0m, float32_121<1,2,1>\u001b[0m], dim=2) -> float32_122<1,2,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[33m\u001b[1m\u001b[7m (!) Max diff 0.00446 (0.561%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/var/folders/hk/7gdln48s6xl6xb4c6183zm6m0000gn/T/ipykernel_80909/2076991626.py\", line 333\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[33m\u001b[1m C \u001b[0m\u001b[90m File \"/var/folders/hk/7gdln48s6xl6xb4c6183zm6m0000gn/T/ipykernel_80909/2076991626.py\", line 23 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[33m\u001b[1maffine_grid[torch.nn.functional]\u001b[0m(float32_116<1,2,3>\u001b[0m, (1, 3, 112, 112)) -> float32_123<1,112,112,2>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[33m\u001b[1m\u001b[7m (!) Max diff 0.00670 (1.511%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/var/folders/hk/7gdln48s6xl6xb4c6183zm6m0000gn/T/ipykernel_80909/2076991626.py\", line 334\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[33m\u001b[1m C \u001b[0m\u001b[90m File \"/var/folders/hk/7gdln48s6xl6xb4c6183zm6m0000gn/T/ipykernel_80909/2076991626.py\", line 23 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[33m\u001b[1maffine_grid[torch.nn.functional]\u001b[0m(float32_122<1,2,3>\u001b[0m, (1, 3, 112, 112)) -> float32_124<1,112,112,2>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mgrid_sample[torch.nn.functional]\u001b[0m(float32_0<1,3,224,224>\u001b[0m, float32_123<1,112,112,2>\u001b[0m) -> float32_125<1,3,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mgrid_sample[torch.nn.functional]\u001b[0m(float32_0<1,3,224,224>\u001b[0m, float32_124<1,112,112,2>\u001b[0m) -> float32_126<1,3,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_125<1,3,112,112>\u001b[0m, float32_126<1,3,112,112>\u001b[0m], dim=0) -> float32_127<2,3,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_127<2,3,112,112>\u001b[0m) -> float32_144<2,32,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_127<2,3,112,112>\u001b[0m) -> float32_130<2,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_127<2,3,112,112>\u001b[0m, float32_128<32,3,3,3>\u001b[0m, float32_129<32>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_130<2,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_130<2,32,112,112>\u001b[0m) -> float32_135<2,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_130<2,32,112,112>\u001b[0m, float32_131<32>\u001b[0m, float32_132<32>\u001b[0m, float32_133<32>\u001b[0m, float32_134<32>\u001b[0m, False, 0.1, 1e-05) -> float32_135<2,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_135<2,32,112,112>\u001b[0m) -> float32_135<2,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_135<2,32,112,112>\u001b[0m, inplace=True) -> float32_135<2,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_135<2,32,112,112>\u001b[0m) -> float32_138<2,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_135<2,32,112,112>\u001b[0m, float32_136<32,32,3,3>\u001b[0m, float32_137<32>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_138<2,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_138<2,32,112,112>\u001b[0m) -> float32_143<2,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_138<2,32,112,112>\u001b[0m, float32_139<32>\u001b[0m, float32_140<32>\u001b[0m, float32_141<32>\u001b[0m, float32_142<32>\u001b[0m, False, 0.1, 1e-05) -> float32_143<2,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_143<2,32,112,112>\u001b[0m) -> float32_143<2,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_143<2,32,112,112>\u001b[0m, inplace=True) -> float32_143<2,32,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_143<2,32,112,112>\u001b[0m) -> float32_144<2,32,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_143<2,32,112,112>\u001b[0m, 2, 2, 0, 1, ceil_mode=False, return_indices=False) -> float32_144<2,32,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_144<2,32,56,56>\u001b[0m) -> float32_161<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_144<2,32,56,56>\u001b[0m) -> float32_147<2,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_144<2,32,56,56>\u001b[0m, float32_145<64,32,3,3>\u001b[0m, float32_146<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_147<2,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_147<2,64,56,56>\u001b[0m) -> float32_152<2,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_147<2,64,56,56>\u001b[0m, float32_148<64>\u001b[0m, float32_149<64>\u001b[0m, float32_150<64>\u001b[0m, float32_151<64>\u001b[0m, False, 0.1, 1e-05) -> float32_152<2,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_152<2,64,56,56>\u001b[0m) -> float32_152<2,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_152<2,64,56,56>\u001b[0m, inplace=True) -> float32_152<2,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_152<2,64,56,56>\u001b[0m) -> float32_155<2,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_152<2,64,56,56>\u001b[0m, float32_153<64,64,3,3>\u001b[0m, float32_154<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_155<2,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_155<2,64,56,56>\u001b[0m) -> float32_160<2,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_155<2,64,56,56>\u001b[0m, float32_156<64>\u001b[0m, float32_157<64>\u001b[0m, float32_158<64>\u001b[0m, float32_159<64>\u001b[0m, False, 0.1, 1e-05) -> float32_160<2,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_160<2,64,56,56>\u001b[0m) -> float32_160<2,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_160<2,64,56,56>\u001b[0m, inplace=True) -> float32_160<2,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_160<2,64,56,56>\u001b[0m) -> float32_161<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_160<2,64,56,56>\u001b[0m, 2, 2, 0, 1, ceil_mode=False, return_indices=False) -> float32_161<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_161<2,64,28,28>\u001b[0m) -> float32_178<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_161<2,64,28,28>\u001b[0m) -> float32_164<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_161<2,64,28,28>\u001b[0m, float32_162<64,64,3,3>\u001b[0m, float32_163<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_164<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_164<2,64,28,28>\u001b[0m) -> float32_169<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_164<2,64,28,28>\u001b[0m, float32_165<64>\u001b[0m, float32_166<64>\u001b[0m, float32_167<64>\u001b[0m, float32_168<64>\u001b[0m, False, 0.1, 1e-05) -> float32_169<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_169<2,64,28,28>\u001b[0m) -> float32_169<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_169<2,64,28,28>\u001b[0m, inplace=True) -> float32_169<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_169<2,64,28,28>\u001b[0m) -> float32_172<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_169<2,64,28,28>\u001b[0m, float32_170<64,64,3,3>\u001b[0m, float32_171<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_172<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_172<2,64,28,28>\u001b[0m) -> float32_177<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_172<2,64,28,28>\u001b[0m, float32_173<64>\u001b[0m, float32_174<64>\u001b[0m, float32_175<64>\u001b[0m, float32_176<64>\u001b[0m, False, 0.1, 1e-05) -> float32_177<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_177<2,64,28,28>\u001b[0m) -> float32_177<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_177<2,64,28,28>\u001b[0m, inplace=True) -> float32_177<2,64,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_177<2,64,28,28>\u001b[0m) -> float32_178<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_177<2,64,28,28>\u001b[0m, 2, 2, 0, 1, ceil_mode=False, return_indices=False) -> float32_178<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_178<2,64,14,14>\u001b[0m) -> float32_195<2,64,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_178<2,64,14,14>\u001b[0m) -> float32_181<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_178<2,64,14,14>\u001b[0m, float32_179<64,64,3,3>\u001b[0m, float32_180<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_181<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_181<2,64,14,14>\u001b[0m) -> float32_186<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_181<2,64,14,14>\u001b[0m, float32_182<64>\u001b[0m, float32_183<64>\u001b[0m, float32_184<64>\u001b[0m, float32_185<64>\u001b[0m, False, 0.1, 1e-05) -> float32_186<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_186<2,64,14,14>\u001b[0m) -> float32_186<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_186<2,64,14,14>\u001b[0m, inplace=True) -> float32_186<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_186<2,64,14,14>\u001b[0m) -> float32_189<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_186<2,64,14,14>\u001b[0m, float32_187<64,64,3,3>\u001b[0m, float32_188<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_189<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_189<2,64,14,14>\u001b[0m) -> float32_194<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_189<2,64,14,14>\u001b[0m, float32_190<64>\u001b[0m, float32_191<64>\u001b[0m, float32_192<64>\u001b[0m, float32_193<64>\u001b[0m, False, 0.1, 1e-05) -> float32_194<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_194<2,64,14,14>\u001b[0m) -> float32_194<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_194<2,64,14,14>\u001b[0m, inplace=True) -> float32_194<2,64,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_194<2,64,14,14>\u001b[0m) -> float32_195<2,64,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_194<2,64,14,14>\u001b[0m, 2, 2, 0, 1, ceil_mode=False, return_indices=False) -> float32_195<2,64,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_195<2,64,7,7>\u001b[0m) -> float32_212<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_195<2,64,7,7>\u001b[0m) -> float32_198<2,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_195<2,64,7,7>\u001b[0m, float32_196<128,64,3,3>\u001b[0m, float32_197<128>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_198<2,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_198<2,128,7,7>\u001b[0m) -> float32_203<2,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_198<2,128,7,7>\u001b[0m, float32_199<128>\u001b[0m, float32_200<128>\u001b[0m, float32_201<128>\u001b[0m, float32_202<128>\u001b[0m, False, 0.1, 1e-05) -> float32_203<2,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_203<2,128,7,7>\u001b[0m) -> float32_203<2,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_203<2,128,7,7>\u001b[0m, inplace=True) -> float32_203<2,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_203<2,128,7,7>\u001b[0m) -> float32_206<2,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_203<2,128,7,7>\u001b[0m, float32_204<128,128,3,3>\u001b[0m, float32_205<128>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_206<2,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_206<2,128,7,7>\u001b[0m) -> float32_211<2,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_206<2,128,7,7>\u001b[0m, float32_207<128>\u001b[0m, float32_208<128>\u001b[0m, float32_209<128>\u001b[0m, float32_210<128>\u001b[0m, False, 0.1, 1e-05) -> float32_211<2,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_211<2,128,7,7>\u001b[0m) -> float32_211<2,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_211<2,128,7,7>\u001b[0m, inplace=True) -> float32_211<2,128,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_211<2,128,7,7>\u001b[0m) -> float32_212<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_211<2,128,7,7>\u001b[0m, 2, 2, 0, 1, ceil_mode=False, return_indices=False) -> float32_212<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_212<2,128,3,3>\u001b[0m) -> float32_212<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_212<2,128,3,3>\u001b[0m, 0.3, False, False) -> float32_212<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_212<2,128,3,3>\u001b[0m) -> float32_228<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_212<2,128,3,3>\u001b[0m) -> float32_215<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_212<2,128,3,3>\u001b[0m, float32_213<128,128,3,3>\u001b[0m, float32_214<128>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_215<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_215<2,128,3,3>\u001b[0m) -> float32_220<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_215<2,128,3,3>\u001b[0m, float32_216<128>\u001b[0m, float32_217<128>\u001b[0m, float32_218<128>\u001b[0m, float32_219<128>\u001b[0m, False, 0.1, 1e-05) -> float32_220<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_220<2,128,3,3>\u001b[0m) -> float32_220<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_220<2,128,3,3>\u001b[0m, inplace=True) -> float32_220<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_220<2,128,3,3>\u001b[0m) -> float32_223<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_220<2,128,3,3>\u001b[0m, float32_221<128,128,3,3>\u001b[0m, float32_222<128>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_223<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_223<2,128,3,3>\u001b[0m) -> float32_228<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_223<2,128,3,3>\u001b[0m, float32_224<128>\u001b[0m, float32_225<128>\u001b[0m, float32_226<128>\u001b[0m, float32_227<128>\u001b[0m, False, 0.1, 1e-05) -> float32_228<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_228<2,128,3,3>\u001b[0m) -> float32_228<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_228<2,128,3,3>\u001b[0m, inplace=True) -> float32_228<2,128,3,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mavg_pool2d[torch.nn.functional]\u001b[0m(float32_228<2,128,3,3>\u001b[0m, 3) -> float32_229<2,128,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_229<2,128,1,1>\u001b[0m, 2, -1) -> float32_230<2,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_230<2,128>\u001b[0m) -> float32_238<2,256>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_230<2,128>\u001b[0m) -> float32_233<2,256>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_230<2,128>\u001b[0m, float32_231<256,128>\u001b[0m, float32_232<256>\u001b[0m) -> float32_233<2,256>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_233<2,256>\u001b[0m) -> float32_238<2,256>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_233<2,256>\u001b[0m, float32_234<256>\u001b[0m, float32_235<256>\u001b[0m, float32_236<256>\u001b[0m, float32_237<256>\u001b[0m, False, 0.1, 1e-05) -> float32_238<2,256>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_238<2,256>\u001b[0m) -> float32_238<2,256>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_238<2,256>\u001b[0m, inplace=True) -> float32_238<2,256>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mdropout[torch.nn.functional]\u001b[0m(float32_238<2,256>\u001b[0m, training=False) -> float32_238<2,256>\u001b[0m\n",
      "\u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_238<2,256>\u001b[0m) -> float32_241<2,4>\u001b[0m\n",
      "\u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_238<2,256>\u001b[0m, float32_239<4,256>\u001b[0m, float32_240<4>\u001b[0m) -> float32_241<2,4>\u001b[0m\n",
      "\n",
      "Conversion complete. Elapsed time: 3.52 sec.\n"
     ]
    }
   ],
   "source": [
    "keras_model = nobuco.pytorch_to_keras(\n",
    "    pytorch_module,\n",
    "    args=[dummy_image], kwargs=None,\n",
    "    inputs_channel_order=ChannelOrder.TENSORFLOW,\n",
    "    outputs_channel_order=ChannelOrder.TENSORFLOW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(1, 224, 224, 3)]           0         []                            \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPaddin  (1, 226, 226, 3)             0         ['input_1[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (1, 224, 224, 32)            896       ['zero_padding2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (1, 224, 224, 32)            128       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (1, 224, 224, 32)            0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadd  (1, 226, 226, 32)            0         ['re_lu[0][0]']               \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (1, 224, 224, 32)            9248      ['zero_padding2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (1, 224, 224, 32)            128       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              (1, 224, 224, 32)            0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (1, 112, 112, 32)            0         ['re_lu_1[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadd  (1, 114, 114, 32)            0         ['max_pooling2d[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (1, 112, 112, 64)            18496     ['zero_padding2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (1, 112, 112, 64)            256       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)              (1, 112, 112, 64)            0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadd  (1, 114, 114, 64)            0         ['re_lu_2[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (1, 112, 112, 64)            36928     ['zero_padding2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (1, 112, 112, 64)            256       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)              (1, 112, 112, 64)            0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (1, 56, 56, 64)              0         ['re_lu_3[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadd  (1, 58, 58, 64)              0         ['max_pooling2d_1[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (1, 56, 56, 64)              36928     ['zero_padding2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (1, 56, 56, 64)              256       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)              (1, 56, 56, 64)              0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadd  (1, 58, 58, 64)              0         ['re_lu_4[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (1, 56, 56, 64)              36928     ['zero_padding2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (1, 56, 56, 64)              256       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)              (1, 56, 56, 64)              0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (1, 28, 28, 64)              0         ['re_lu_5[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " zero_padding2d_6 (ZeroPadd  (1, 30, 30, 64)              0         ['max_pooling2d_2[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (1, 28, 28, 64)              36928     ['zero_padding2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (1, 28, 28, 64)              256       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)              (1, 28, 28, 64)              0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " zero_padding2d_7 (ZeroPadd  (1, 30, 30, 64)              0         ['re_lu_6[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (1, 28, 28, 64)              36928     ['zero_padding2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (1, 28, 28, 64)              256       ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)              (1, 28, 28, 64)              0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (1, 14, 14, 64)              0         ['re_lu_7[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " zero_padding2d_8 (ZeroPadd  (1, 16, 16, 64)              0         ['max_pooling2d_3[0][0]']     \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (1, 14, 14, 128)             73856     ['zero_padding2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (1, 14, 14, 128)             512       ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)              (1, 14, 14, 128)             0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " zero_padding2d_9 (ZeroPadd  (1, 16, 16, 128)             0         ['re_lu_8[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (1, 14, 14, 128)             147584    ['zero_padding2d_9[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (1, 14, 14, 128)             512       ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)              (1, 14, 14, 128)             0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (1, 7, 7, 128)               0         ['re_lu_9[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (1, 7, 7, 128)               0         ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " zero_padding2d_10 (ZeroPad  (1, 9, 9, 128)               0         ['dropout[0][0]']             \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (1, 7, 7, 128)               147584    ['zero_padding2d_10[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (1, 7, 7, 128)               512       ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)             (1, 7, 7, 128)               0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_11 (ZeroPad  (1, 9, 9, 128)               0         ['re_lu_10[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (1, 7, 7, 128)               147584    ['zero_padding2d_11[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (1, 7, 7, 128)               512       ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)             (1, 7, 7, 128)               0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TF  (1, 128, 7, 7)               0         ['re_lu_11[0][0]']            \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)     (1, 6272)                    0         ['tf.compat.v1.transpose[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (1, 32)                      200736    ['tf.reshape[0][0]']          \n",
      "                                                                                                  \n",
      " weight_layer (WeightLayer)  (2, 2)                       4         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)             (1, 32)                      0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " weight_layer_1 (WeightLaye  (2, 2)                       4         ['input_1[0][0]']             \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (2, 2)                       0         ['weight_layer[0][0]']        \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (1, 4)                       132       ['re_lu_12[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (2, 2)                       0         ['weight_layer_1[0][0]']      \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)   (1, 2, 2)                    0         ['tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " tf.split (TFOpLambda)       [(1, 2),                     0         ['dense_1[0][0]']             \n",
      "                              (1, 2)]                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_3 (TFOpLambda)   (1, 2, 2)                    0         ['tf.math.multiply_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.tile (TFOpLambda)        (1, 2, 2)                    0         ['tf.reshape_1[0][0]']        \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)   (1, 2, 1)                    0         ['tf.split[0][0]']            \n",
      "                                                                                                  \n",
      " tf.tile_1 (TFOpLambda)      (1, 2, 2)                    0         ['tf.reshape_3[0][0]']        \n",
      "                                                                                                  \n",
      " tf.reshape_4 (TFOpLambda)   (1, 2, 1)                    0         ['tf.split[0][0]']            \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (1, 2, 3)                    0         ['tf.tile[0][0]',             \n",
      "                                                                     'tf.reshape_2[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)    (1, 2, 3)                    0         ['tf.tile_1[0][0]',           \n",
      "                                                                     'tf.reshape_4[0][0]']        \n",
      "                                                                                                  \n",
      " tf.reshape_5 (TFOpLambda)   (1, 2, 3)                    0         ['tf.concat[0][0]']           \n",
      "                                                                                                  \n",
      " tf.reshape_7 (TFOpLambda)   (1, 2, 3)                    0         ['tf.concat_1[0][0]']         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_1 (  (1, 3, 2)                    0         ['tf.reshape_5[0][0]']        \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_2 (  (1, 3, 2)                    0         ['tf.reshape_7[0][0]']        \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.linalg.matmul (TFOpLamb  (1, 12544, 2)                0         ['tf.compat.v1.transpose_1[0][\n",
      " da)                                                                0]']                          \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_1 (TFOpLa  (1, 12544, 2)                0         ['tf.compat.v1.transpose_2[0][\n",
      " mbda)                                                              0]']                          \n",
      "                                                                                                  \n",
      " tf.reshape_6 (TFOpLambda)   (1, 112, 112, 2)             0         ['tf.linalg.matmul[0][0]']    \n",
      "                                                                                                  \n",
      " tf.reshape_8 (TFOpLambda)   (1, 112, 112, 2)             0         ['tf.linalg.matmul_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_3 (  (1, 112, 2, 112)             0         ['tf.reshape_6[0][0]']        \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLa  (4,)                         0         ['input_1[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_5 (  (1, 112, 2, 112)             0         ['tf.reshape_8[0][0]']        \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['input_1[0][0]']             \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_4 (  (1, 112, 112, 2)             0         ['tf.compat.v1.transpose_3[0][\n",
      " TFOpLambda)                                                        0]']                          \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)        (4,)                         0         ['tf.compat.v1.shape[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_6 (  (1, 112, 112, 2)             0         ['tf.compat.v1.transpose_5[0][\n",
      " TFOpLambda)                                                        0]']                          \n",
      "                                                                                                  \n",
      " tf.cast_5 (TFOpLambda)      (4,)                         0         ['tf.compat.v1.shape_1[0][0]']\n",
      "                                                                                                  \n",
      " tf.split_1 (TFOpLambda)     [(1, 112, 112, 1),           0         ['tf.compat.v1.transpose_4[0][\n",
      "                              (1, 112, 112, 1)]                     0]']                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.cast[0][0]']             \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.split_2 (TFOpLambda)     [(1, 112, 112, 1),           0         ['tf.compat.v1.transpose_6[0][\n",
      "                              (1, 112, 112, 1)]                     0]']                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5  ()                           0         ['tf.cast_5[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.add_2 (TFOpLambda)  (1, 112, 112, 1)             0         ['tf.split_1[0][1]']          \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLa  ()                           0         ['tf.__operators__.getitem_1[0\n",
      " mbda)                                                              ][0]']                        \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.cast[0][0]']             \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.add_14 (TFOpLambda  (1, 112, 112, 1)             0         ['tf.split_2[0][1]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_24 (TFOpL  ()                           0         ['tf.__operators__.getitem_5[0\n",
      " ambda)                                                             ][0]']                        \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6  ()                           0         ['tf.cast_5[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.add_2[0][0]',       \n",
      " mbda)                                                               'tf.math.multiply_4[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.add (TFOpLambda)    (1, 112, 112, 1)             0         ['tf.split_1[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLa  ()                           0         ['tf.__operators__.getitem_2[0\n",
      " mbda)                                                              ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.multiply_25 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.add_14[0][0]',      \n",
      " ambda)                                                              'tf.math.multiply_24[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.add_12 (TFOpLambda  (1, 112, 112, 1)             0         ['tf.split_2[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_22 (TFOpL  ()                           0         ['tf.__operators__.getitem_6[0\n",
      " ambda)                                                             ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.multiply_5[0][0]']  \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.add[0][0]',         \n",
      " mbda)                                                               'tf.math.multiply_2[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.subtract_7 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.multiply_25[0][0]'] \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_23 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.add_12[0][0]',      \n",
      " ambda)                                                              'tf.math.multiply_22[0][0]'] \n",
      "                                                                                                  \n",
      " tf.clip_by_value_1 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.subtract_1[0][0]',  \n",
      " mbda)                                                               'tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLamb  (1, 112, 112, 1)             0         ['tf.math.multiply_3[0][0]']  \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.clip_by_value_3 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.subtract_7[0][0]',  \n",
      " mbda)                                                               'tf.__operators__.getitem_5[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.subtract_6 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.multiply_23[0][0]'] \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.add_3 (TFOpLambda)  (1, 112, 112, 1)             0         ['tf.clip_by_value_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.clip_by_value (TFOpLamb  (1, 112, 112, 1)             0         ['tf.math.subtract[0][0]',    \n",
      " da)                                                                 'tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.add_15 (TFOpLambda  (1, 112, 112, 1)             0         ['tf.clip_by_value_3[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.clip_by_value_2 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.subtract_6[0][0]',  \n",
      " mbda)                                                               'tf.__operators__.getitem_6[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.floor_1 (TFOpLambd  (1, 112, 112, 1)             0         ['tf.math.add_3[0][0]']       \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.add_1 (TFOpLambda)  (1, 112, 112, 1)             0         ['tf.clip_by_value[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.add_4 (TFOpLambda)  ()                           0         ['tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.add_6 (TFOpLambda)  ()                           0         ['tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.ceil_1 (TFOpLambda  (1, 112, 112, 1)             0         ['tf.math.add_3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.floor_3 (TFOpLambd  (1, 112, 112, 1)             0         ['tf.math.add_15[0][0]']      \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.add_13 (TFOpLambda  (1, 112, 112, 1)             0         ['tf.clip_by_value_2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.add_16 (TFOpLambda  ()                           0         ['tf.__operators__.getitem_6[0\n",
      " )                                                                  ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.add_18 (TFOpLambda  ()                           0         ['tf.__operators__.getitem_6[0\n",
      " )                                                                  ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.ceil_3 (TFOpLambda  (1, 112, 112, 1)             0         ['tf.math.add_15[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.floor (TFOpLambda)  (1, 112, 112, 1)             0         ['tf.math.add_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.floor_1[0][0]',     \n",
      " ambda)                                                              'tf.math.add_4[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.ceil_1[0][0]',      \n",
      " ambda)                                                              'tf.math.add_6[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.add_8 (TFOpLambda)  ()                           0         ['tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.floor_2 (TFOpLambd  (1, 112, 112, 1)             0         ['tf.math.add_13[0][0]']      \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_30 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.floor_3[0][0]',     \n",
      " ambda)                                                              'tf.math.add_16[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_32 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.ceil_3[0][0]',      \n",
      " ambda)                                                              'tf.math.add_18[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.add_20 (TFOpLambda  ()                           0         ['tf.__operators__.getitem_6[0\n",
      " )                                                                  ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.add_5 (TFOpLambda)  ()                           0         ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (1, 112, 112, 1)             0         ['tf.math.multiply_10[0][0]', \n",
      " Lambda)                                                             'tf.math.floor[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.add_7 (TFOpLambda)  ()                           0         ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (1, 112, 112, 1)             0         ['tf.math.multiply_12[0][0]', \n",
      " OpLambda)                                                           'tf.math.floor[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.ceil_1[0][0]',      \n",
      " ambda)                                                              'tf.math.add_8[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.ceil (TFOpLambda)   (1, 112, 112, 1)             0         ['tf.math.add_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.add_10 (TFOpLambda  ()                           0         ['tf.__operators__.getitem_2[0\n",
      " )                                                                  ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.add_17 (TFOpLambda  ()                           0         ['tf.__operators__.getitem_5[0\n",
      " )                                                                  ][0]']                        \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (1, 112, 112, 1)             0         ['tf.math.multiply_30[0][0]', \n",
      " OpLambda)                                                           'tf.math.floor_2[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.add_19 (TFOpLambda  ()                           0         ['tf.__operators__.getitem_5[0\n",
      " )                                                                  ][0]']                        \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TF  (1, 112, 112, 1)             0         ['tf.math.multiply_32[0][0]', \n",
      " OpLambda)                                                           'tf.math.floor_2[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_34 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.ceil_3[0][0]',      \n",
      " ambda)                                                              'tf.math.add_20[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.ceil_2 (TFOpLambda  (1, 112, 112, 1)             0         ['tf.math.add_13[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.add_22 (TFOpLambda  ()                           0         ['tf.__operators__.getitem_6[0\n",
      " )                                                                  ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.subtract_3 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.add_3[0][0]',       \n",
      " mbda)                                                               'tf.math.floor_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.add_1[0][0]',       \n",
      " mbda)                                                               'tf.math.floor[0][0]']       \n",
      "                                                                                                  \n",
      " zero_padding2d_28 (ZeroPad  (1, 226, 226, 3)             0         ['input_1[0][0]']             \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  ()                           0         ['tf.cast[0][0]']             \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpL  ()                           0         ['tf.math.add_5[0][0]',       \n",
      " ambda)                                                              'tf.math.add_4[0][0]']       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  ()                           0         ['tf.cast[0][0]']             \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)      (1, 112, 112, 1)             0         ['tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambd  ()                           0         ['tf.__operators__.getitem_1[0\n",
      " a)                                                                 ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.truediv_1 (TFOpLam  ()                           0         ['tf.__operators__.getitem_2[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpL  ()                           0         ['tf.math.add_7[0][0]',       \n",
      " ambda)                                                              'tf.math.add_6[0][0]']       \n",
      "                                                                                                  \n",
      " tf.cast_2 (TFOpLambda)      (1, 112, 112, 1)             0         ['tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.truediv_2 (TFOpLam  ()                           0         ['tf.__operators__.getitem_1[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.truediv_3 (TFOpLam  ()                           0         ['tf.__operators__.getitem_2[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.add_9 (TFOpLambda)  ()                           0         ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (1, 112, 112, 1)             0         ['tf.math.multiply_14[0][0]', \n",
      " OpLambda)                                                           'tf.math.ceil[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply_16 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.floor_1[0][0]',     \n",
      " ambda)                                                              'tf.math.add_10[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.subtract_9 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.add_15[0][0]',      \n",
      " mbda)                                                               'tf.math.floor_3[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.subtract_8 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.add_13[0][0]',      \n",
      " mbda)                                                               'tf.math.floor_2[0][0]']     \n",
      "                                                                                                  \n",
      " zero_padding2d_29 (ZeroPad  (1, 226, 226, 3)             0         ['input_1[0][0]']             \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4  ()                           0         ['tf.cast_5[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_31 (TFOpL  ()                           0         ['tf.math.add_17[0][0]',      \n",
      " ambda)                                                              'tf.math.add_16[0][0]']      \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7  ()                           0         ['tf.cast_5[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.cast_6 (TFOpLambda)      (1, 112, 112, 1)             0         ['tf.__operators__.add_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.truediv_8 (TFOpLam  ()                           0         ['tf.__operators__.getitem_5[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.truediv_9 (TFOpLam  ()                           0         ['tf.__operators__.getitem_6[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.multiply_33 (TFOpL  ()                           0         ['tf.math.add_19[0][0]',      \n",
      " ambda)                                                              'tf.math.add_18[0][0]']      \n",
      "                                                                                                  \n",
      " tf.cast_7 (TFOpLambda)      (1, 112, 112, 1)             0         ['tf.__operators__.add_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.truediv_10 (TFOpLa  ()                           0         ['tf.__operators__.getitem_5[0\n",
      " mbda)                                                              ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.truediv_11 (TFOpLa  ()                           0         ['tf.__operators__.getitem_6[0\n",
      " mbda)                                                              ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.add_21 (TFOpLambda  ()                           0         ['tf.__operators__.getitem_5[0\n",
      " )                                                                  ][0]']                        \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TF  (1, 112, 112, 1)             0         ['tf.math.multiply_34[0][0]', \n",
      " OpLambda)                                                           'tf.math.ceil_2[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_36 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.floor_3[0][0]',     \n",
      " ambda)                                                              'tf.math.add_22[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.subtract_5 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.subtract_3[0][0]']  \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.subtract_4 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.subtract_2[0][0]']  \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.reshape_10 (TFOpLambda)  (None, None, None)           0         ['zero_padding2d_28[0][0]',   \n",
      "                                                                     'tf.__operators__.getitem[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'tf.math.multiply_11[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_9 (TFOpLambda)   (None, None, None)           0         ['tf.cast_1[0][0]',           \n",
      "                                                                     'tf.__operators__.getitem[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'tf.math.truediv[0][0]',     \n",
      "                                                                     'tf.math.truediv_1[0][0]']   \n",
      "                                                                                                  \n",
      " tf.reshape_12 (TFOpLambda)  (None, None, None)           0         ['zero_padding2d_28[0][0]',   \n",
      "                                                                     'tf.__operators__.getitem[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'tf.math.multiply_13[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_11 (TFOpLambda)  (None, None, None)           0         ['tf.cast_2[0][0]',           \n",
      "                                                                     'tf.__operators__.getitem[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'tf.math.truediv_2[0][0]',   \n",
      "                                                                     'tf.math.truediv_3[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpL  ()                           0         ['tf.math.add_9[0][0]',       \n",
      " ambda)                                                              'tf.math.add_8[0][0]']       \n",
      "                                                                                                  \n",
      " tf.cast_3 (TFOpLambda)      (1, 112, 112, 1)             0         ['tf.__operators__.add_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.truediv_4 (TFOpLam  ()                           0         ['tf.__operators__.getitem_1[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.truediv_5 (TFOpLam  ()                           0         ['tf.__operators__.getitem_2[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.add_11 (TFOpLambda  ()                           0         ['tf.__operators__.getitem_1[0\n",
      " )                                                                  ][0]']                        \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (1, 112, 112, 1)             0         ['tf.math.multiply_16[0][0]', \n",
      " OpLambda)                                                           'tf.math.ceil[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.subtract_11 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.subtract_9[0][0]']  \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.math.subtract_10 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.subtract_8[0][0]']  \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.reshape_18 (TFOpLambda)  (None, None, None)           0         ['zero_padding2d_29[0][0]',   \n",
      "                                                                     'tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.math.multiply_31[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_7[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_17 (TFOpLambda)  (None, None, None)           0         ['tf.cast_6[0][0]',           \n",
      "                                                                     'tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.math.truediv_8[0][0]',   \n",
      "                                                                     'tf.math.truediv_9[0][0]']   \n",
      "                                                                                                  \n",
      " tf.reshape_20 (TFOpLambda)  (None, None, None)           0         ['zero_padding2d_29[0][0]',   \n",
      "                                                                     'tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.math.multiply_33[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_7[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_19 (TFOpLambda)  (None, None, None)           0         ['tf.cast_7[0][0]',           \n",
      "                                                                     'tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.math.truediv_10[0][0]',  \n",
      "                                                                     'tf.math.truediv_11[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.multiply_35 (TFOpL  ()                           0         ['tf.math.add_21[0][0]',      \n",
      " ambda)                                                              'tf.math.add_20[0][0]']      \n",
      "                                                                                                  \n",
      " tf.cast_8 (TFOpLambda)      (1, 112, 112, 1)             0         ['tf.__operators__.add_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.truediv_12 (TFOpLa  ()                           0         ['tf.__operators__.getitem_5[0\n",
      " mbda)                                                              ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.truediv_13 (TFOpLa  ()                           0         ['tf.__operators__.getitem_6[0\n",
      " mbda)                                                              ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.add_23 (TFOpLambda  ()                           0         ['tf.__operators__.getitem_5[0\n",
      " )                                                                  ][0]']                        \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (T  (1, 112, 112, 1)             0         ['tf.math.multiply_36[0][0]', \n",
      " FOpLambda)                                                          'tf.math.ceil_2[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.subtract_5[0][0]',  \n",
      " mbda)                                                               'tf.math.subtract_4[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather (TFOpL  (None, None, None, None)     0         ['tf.reshape_10[0][0]',       \n",
      " ambda)                                                              'tf.reshape_9[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.subtract_3[0][0]',  \n",
      " mbda)                                                               'tf.math.subtract_4[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_1 (TFO  (None, None, None, None)     0         ['tf.reshape_12[0][0]',       \n",
      " pLambda)                                                            'tf.reshape_11[0][0]']       \n",
      "                                                                                                  \n",
      " tf.reshape_14 (TFOpLambda)  (None, None, None)           0         ['zero_padding2d_28[0][0]',   \n",
      "                                                                     'tf.__operators__.getitem[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'tf.math.multiply_15[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_13 (TFOpLambda)  (None, None, None)           0         ['tf.cast_3[0][0]',           \n",
      "                                                                     'tf.__operators__.getitem[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'tf.math.truediv_4[0][0]',   \n",
      "                                                                     'tf.math.truediv_5[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.multiply_17 (TFOpL  ()                           0         ['tf.math.add_11[0][0]',      \n",
      " ambda)                                                              'tf.math.add_10[0][0]']      \n",
      "                                                                                                  \n",
      " tf.cast_4 (TFOpLambda)      (1, 112, 112, 1)             0         ['tf.__operators__.add_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.truediv_6 (TFOpLam  ()                           0         ['tf.__operators__.getitem_1[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.truediv_7 (TFOpLam  ()                           0         ['tf.__operators__.getitem_2[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.multiply_26 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.subtract_11[0][0]', \n",
      " ambda)                                                              'tf.math.subtract_10[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_4 (TFO  (None, None, None, None)     0         ['tf.reshape_18[0][0]',       \n",
      " pLambda)                                                            'tf.reshape_17[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_27 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.subtract_9[0][0]',  \n",
      " ambda)                                                              'tf.math.subtract_10[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_5 (TFO  (None, None, None, None)     0         ['tf.reshape_20[0][0]',       \n",
      " pLambda)                                                            'tf.reshape_19[0][0]']       \n",
      "                                                                                                  \n",
      " tf.reshape_22 (TFOpLambda)  (None, None, None)           0         ['zero_padding2d_29[0][0]',   \n",
      "                                                                     'tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.math.multiply_35[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_7[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_21 (TFOpLambda)  (None, None, None)           0         ['tf.cast_8[0][0]',           \n",
      "                                                                     'tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.math.truediv_12[0][0]',  \n",
      "                                                                     'tf.math.truediv_13[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.multiply_37 (TFOpL  ()                           0         ['tf.math.add_23[0][0]',      \n",
      " ambda)                                                              'tf.math.add_22[0][0]']      \n",
      "                                                                                                  \n",
      " tf.cast_9 (TFOpLambda)      (1, 112, 112, 1)             0         ['tf.__operators__.add_10[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.truediv_14 (TFOpLa  ()                           0         ['tf.__operators__.getitem_5[0\n",
      " mbda)                                                              ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.truediv_15 (TFOpLa  ()                           0         ['tf.__operators__.getitem_6[0\n",
      " mbda)                                                              ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.multiply_18 (TFOpL  (None, 112, 112, None)       0         ['tf.math.multiply_6[0][0]',  \n",
      " ambda)                                                              'tf.compat.v1.gather[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_19 (TFOpL  (None, 112, 112, None)       0         ['tf.math.multiply_7[0][0]',  \n",
      " ambda)                                                              'tf.compat.v1.gather_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.subtract_3[0][0]',  \n",
      " mbda)                                                               'tf.math.subtract_2[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_2 (TFO  (None, None, None, None)     0         ['tf.reshape_14[0][0]',       \n",
      " pLambda)                                                            'tf.reshape_13[0][0]']       \n",
      "                                                                                                  \n",
      " tf.reshape_16 (TFOpLambda)  (None, None, None)           0         ['zero_padding2d_28[0][0]',   \n",
      "                                                                     'tf.__operators__.getitem[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'tf.math.multiply_17[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_15 (TFOpLambda)  (None, None, None)           0         ['tf.cast_4[0][0]',           \n",
      "                                                                     'tf.__operators__.getitem[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'tf.math.truediv_6[0][0]',   \n",
      "                                                                     'tf.math.truediv_7[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.multiply_38 (TFOpL  (None, 112, 112, None)       0         ['tf.math.multiply_26[0][0]', \n",
      " ambda)                                                              'tf.compat.v1.gather_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.math.multiply_39 (TFOpL  (None, 112, 112, None)       0         ['tf.math.multiply_27[0][0]', \n",
      " ambda)                                                              'tf.compat.v1.gather_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.math.multiply_28 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.subtract_9[0][0]',  \n",
      " ambda)                                                              'tf.math.subtract_8[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_6 (TFO  (None, None, None, None)     0         ['tf.reshape_22[0][0]',       \n",
      " pLambda)                                                            'tf.reshape_21[0][0]']       \n",
      "                                                                                                  \n",
      " tf.reshape_24 (TFOpLambda)  (None, None, None)           0         ['zero_padding2d_29[0][0]',   \n",
      "                                                                     'tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.math.multiply_37[0][0]', \n",
      "                                                                     'tf.__operators__.getitem_7[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_23 (TFOpLambda)  (None, None, None)           0         ['tf.cast_9[0][0]',           \n",
      "                                                                     'tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.math.truediv_14[0][0]',  \n",
      "                                                                     'tf.math.truediv_15[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (None, 112, 112, None)       0         ['tf.math.multiply_18[0][0]', \n",
      " OpLambda)                                                           'tf.math.multiply_19[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_20 (TFOpL  (None, 112, 112, None)       0         ['tf.math.multiply_8[0][0]',  \n",
      " ambda)                                                              'tf.compat.v1.gather_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLa  (1, 112, 112, 1)             0         ['tf.math.subtract_5[0][0]',  \n",
      " mbda)                                                               'tf.math.subtract_2[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_3 (TFO  (None, None, None, None)     0         ['tf.reshape_16[0][0]',       \n",
      " pLambda)                                                            'tf.reshape_15[0][0]']       \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (T  (None, 112, 112, None)       0         ['tf.math.multiply_38[0][0]', \n",
      " FOpLambda)                                                          'tf.math.multiply_39[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_40 (TFOpL  (None, 112, 112, None)       0         ['tf.math.multiply_28[0][0]', \n",
      " ambda)                                                              'tf.compat.v1.gather_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.math.multiply_29 (TFOpL  (1, 112, 112, 1)             0         ['tf.math.subtract_11[0][0]', \n",
      " ambda)                                                              'tf.math.subtract_8[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_7 (TFO  (None, None, None, None)     0         ['tf.reshape_24[0][0]',       \n",
      " pLambda)                                                            'tf.reshape_23[0][0]']       \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TF  (None, 112, 112, None)       0         ['tf.__operators__.add_4[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'tf.math.multiply_20[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_21 (TFOpL  (None, 112, 112, None)       0         ['tf.math.multiply_9[0][0]',  \n",
      " ambda)                                                              'tf.compat.v1.gather_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (T  (None, 112, 112, None)       0         ['tf.__operators__.add_11[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'tf.math.multiply_40[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_41 (TFOpL  (None, 112, 112, None)       0         ['tf.math.multiply_29[0][0]', \n",
      " ambda)                                                              'tf.compat.v1.gather_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (None, 112, 112, None)       0         ['tf.__operators__.add_5[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'tf.math.multiply_21[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (T  (None, 112, 112, None)       0         ['tf.__operators__.add_12[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'tf.math.multiply_41[0][0]'] \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)    (None, 112, 112, None)       0         ['tf.__operators__.add_6[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_13[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_14 (ZeroPad  (None, 114, 114, None)       0         ['tf.concat_2[0][0]']         \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 112, 112, 32)         896       ['zero_padding2d_14[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 112, 112, 32)         128       ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)             (None, 112, 112, 32)         0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_15 (ZeroPad  (None, 114, 114, 32)         0         ['re_lu_13[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 112, 112, 32)         9248      ['zero_padding2d_15[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 112, 112, 32)         128       ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)             (None, 112, 112, 32)         0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 56, 56, 32)           0         ['re_lu_14[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " zero_padding2d_16 (ZeroPad  (None, 58, 58, 32)           0         ['max_pooling2d_5[0][0]']     \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 56, 56, 64)           18496     ['zero_padding2d_16[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 56, 56, 64)           256       ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)             (None, 56, 56, 64)           0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_17 (ZeroPad  (None, 58, 58, 64)           0         ['re_lu_15[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 56, 56, 64)           36928     ['zero_padding2d_17[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 56, 56, 64)           256       ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)             (None, 56, 56, 64)           0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 28, 28, 64)           0         ['re_lu_16[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " zero_padding2d_18 (ZeroPad  (None, 30, 30, 64)           0         ['max_pooling2d_6[0][0]']     \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 28, 28, 64)           36928     ['zero_padding2d_18[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 28, 28, 64)           256       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)             (None, 28, 28, 64)           0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_19 (ZeroPad  (None, 30, 30, 64)           0         ['re_lu_17[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 28, 28, 64)           36928     ['zero_padding2d_19[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 28, 28, 64)           256       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)             (None, 28, 28, 64)           0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 14, 14, 64)           0         ['re_lu_18[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " zero_padding2d_20 (ZeroPad  (None, 16, 16, 64)           0         ['max_pooling2d_7[0][0]']     \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 14, 14, 64)           36928     ['zero_padding2d_20[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 14, 14, 64)           256       ['conv2d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)             (None, 14, 14, 64)           0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_21 (ZeroPad  (None, 16, 16, 64)           0         ['re_lu_19[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 14, 14, 64)           36928     ['zero_padding2d_21[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 14, 14, 64)           256       ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)             (None, 14, 14, 64)           0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 7, 7, 64)             0         ['re_lu_20[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " zero_padding2d_22 (ZeroPad  (None, 9, 9, 64)             0         ['max_pooling2d_8[0][0]']     \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 7, 7, 128)            73856     ['zero_padding2d_22[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 7, 7, 128)            512       ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)             (None, 7, 7, 128)            0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_23 (ZeroPad  (None, 9, 9, 128)            0         ['re_lu_21[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 7, 7, 128)            147584    ['zero_padding2d_23[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 7, 7, 128)            512       ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)             (None, 7, 7, 128)            0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 3, 3, 128)            0         ['re_lu_22[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 3, 3, 128)            0         ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " zero_padding2d_24 (ZeroPad  (None, 5, 5, 128)            0         ['dropout_1[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 3, 3, 128)            147584    ['zero_padding2d_24[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 3, 3, 128)            512       ['conv2d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)             (None, 3, 3, 128)            0         ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_25 (ZeroPad  (None, 5, 5, 128)            0         ['re_lu_23[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 3, 3, 128)            147584    ['zero_padding2d_25[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 3, 3, 128)            512       ['conv2d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)             (None, 3, 3, 128)            0         ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (None, 1, 1, 128)            0         ['re_lu_24[0][0]']            \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_7 (  (None, 128, 1, 1)            0         ['average_pooling2d[0][0]']   \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.reshape_25 (TFOpLambda)  (2, None)                    0         ['tf.compat.v1.transpose_7[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (2, 256)                     33024     ['tf.reshape_25[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (2, 256)                     1024      ['dense_2[0][0]']             \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)             (2, 256)                     0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (2, 256)                     0         ['re_lu_25[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (2, 4)                       1028      ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " tf.identity (TFOpLambda)    (2, 4)                       0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1703408 (6.50 MB)\n",
      "Trainable params: 1699056 (6.48 MB)\n",
      "Non-trainable params: 4352 (17.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x2f228a250>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: roymodel_tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: roymodel_tf/assets\n"
     ]
    }
   ],
   "source": [
    "# json_config = keras_model.to_json()\n",
    "# keras_model.save(\"roymodel.h5\")\n",
    "# keras_model.save(\"roymodel.keras\")\n",
    "tf.keras.models.save_model(keras_model, \"roymodel_tf\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# new_model = tf.keras.models.model_from_json(json_config, custom_objects={\"WeightLayer\": WeightLayer})\n",
    "# new_model = tf.keras.models.load_model(\"roymodel.h5\", custom_objects={\"WeightLayer\": WeightLayer})\n",
    "# new_model = tf.keras.models.load_model(\"roymodel.keras\", custom_objects={\"WeightLayer\": WeightLayer})\n",
    "new_model = tf.keras.models.load_model(\"roymodel_tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STN tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Definizione della trasformazione affine (ad esempio una rotazione di 45 gradi)\n",
    "theta = torch.tensor([[math.cos(math.pi/3), -math.sin(math.pi/3), 0],\n",
    "                      [math.sin(math.pi/3), math.cos(math.pi/3), 0]])\n",
    "\n",
    "# Definizione della dimensione della griglia\n",
    "size = torch.Size([1, 3, 112, 112])  # Immagine 28x28\n",
    "\n",
    "# Creazione della griglia di coordinate affine\n",
    "grid = F.affine_grid(theta.unsqueeze(0), size)\n",
    "\n",
    "# Esempio di utilizzo: applicare un'immagine di input alla griglia di coordinate\n",
    "input_image = torch.randn(1, 3, 112, 112)  # Immagine di input 28x28\n",
    "output_image = F.grid_sample(input_image, grid)\n",
    "\n",
    "# Spostiamo il tensore su CPU e lo convertiamo in un array numpy\n",
    "image_np = output_image.cpu().detach().numpy()\n",
    "\n",
    "# Trasformiamo l'immagine in formato CHW (canale, altezza, larghezza) in formato HWC (altezza, larghezza, canale)\n",
    "image_np = np.transpose(image_np, (0, 2, 3, 1))\n",
    "\n",
    "# Assicuriamoci che i valori dei pixel siano compresi tra 0 e 1\n",
    "image_np = np.clip(image_np, 0, 1)\n",
    "\n",
    "# Stampa dell'immagine\n",
    "plt.imshow(image_np[0])  # Selezioniamo il primo batch (indice 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full PyTorch without F.grid_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "def grid_sample(input, grid):\n",
    "    def process_coord(grid, w_h):\n",
    "        pixs = (grid + 1) * (0.5 * w_h) - 0.5\n",
    "        pixs = torch.clamp(pixs, -1, w_h) + 1\n",
    "        return pixs\n",
    "\n",
    "    def gather(input, y, x, b, h, w, c):\n",
    "        w_padded = w + 2  # Calculate padded width\n",
    "        h_padded = h + 2  # Calculate padded height\n",
    "\n",
    "        # Combine y and x coordinates into a single tensor\n",
    "        xy_coords = torch.stack([y, x], dim=2)  # Concatenate across channels\n",
    "\n",
    "        # Reshape xy_coords to match the input's batch dimension (b, h, w, 2)\n",
    "        xy_coords = xy_coords.reshape(b, h, w, 2)\n",
    "\n",
    "        # Flatten input tensor to a 2D tensor for efficient gathering (b, h_padded * w_padded * c)\n",
    "        input_flat = input.view(b, -1, c)\n",
    "\n",
    "        # Ensure xy_coords has dtype of torch.int64 for compatibility with gather\n",
    "        xy_coords = xy_coords.long()  # Cast xy_coords to torch.int64\n",
    "\n",
    "        # Gather elements based on xy_coords\n",
    "        out = torch.gather(input_flat, dim=1, index=xy_coords.view(b, -1, 2))\n",
    "\n",
    "        # Reshape the output to match the original dimensions (b, h, w, c)\n",
    "        out = out.view(b, h, w, c)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    b, c, h, w = input.size()\n",
    "\n",
    "    grid_x, grid_y = torch.chunk(grid, chunks=2, dim=-1)\n",
    "    x = process_coord(grid_x, w)\n",
    "    y = process_coord(grid_y, h)\n",
    "\n",
    "    input = torch.nn.ZeroPad2d(padding=(1, 1))(input)\n",
    "\n",
    "    x0 = torch.floor(x)\n",
    "    y0 = torch.floor(y)\n",
    "    x1 = torch.ceil(x)\n",
    "    y1 = torch.ceil(y)\n",
    "\n",
    "    dx = x - x0\n",
    "    dy = y - y0\n",
    "    oneminus_dx = 1 - dx\n",
    "    oneminus_dy = 1 - dy\n",
    "    w_y0_x0 = oneminus_dy * oneminus_dx\n",
    "    w_y1_x0 = dy * oneminus_dx\n",
    "    w_y1_x1 = dy * dx\n",
    "    w_y0_x1 = oneminus_dy * dx\n",
    "\n",
    "    v_y0_x0 = gather(input, y0, x0, b, h, w, c)\n",
    "    v_y1_x0 = gather(input, y1, x0, b, h, w, c)\n",
    "    v_y1_x1 = gather(input, y1, x1, b, h, w, c)\n",
    "    v_y0_x1 = gather(input, y0, x1, b, h, w, c)\n",
    "\n",
    "    return w_y0_x0 * v_y0_x0 + w_y1_x0 * v_y1_x0 + w_y1_x1 * v_y1_x1 + w_y0_x1 * v_y0_x1\n",
    "\n",
    "\n",
    "# Definizione della trasformazione affine (ad esempio una rotazione di 45 gradi)\n",
    "theta = torch.tensor([[math.cos(math.pi/3), -math.sin(math.pi/3), 0],\n",
    "                      [math.sin(math.pi/3), math.cos(math.pi/3), 0]])\n",
    "\n",
    "# Definizione della dimensione della griglia\n",
    "size = torch.Size([1, 3, 112, 112])  # Immagine 28x28\n",
    "\n",
    "# Creazione della griglia di coordinate affine\n",
    "grid = F.affine_grid(theta.unsqueeze(0), size)\n",
    "\n",
    "# Esempio di utilizzo: applicare un'immagine di input alla griglia di coordinate\n",
    "input_image = torch.randn(1, 3, 112, 112)  # Immagine di input 28x28\n",
    "# output_image = F.grid_sample(input_image, grid)\n",
    "output_image = grid_sample(input_image, grid)\n",
    "\n",
    "# Spostiamo il tensore su CPU e lo convertiamo in un array numpy\n",
    "image_np = output_image.cpu().detach().numpy()\n",
    "\n",
    "print(image_np.shape)\n",
    "\n",
    "# Trasformiamo l'immagine in formato CHW (canale, altezza, larghezza) in formato HWC (altezza, larghezza, canale)\n",
    "image_np = np.transpose(image_np, (0, 3, 2, 1))\n",
    "\n",
    "# Assicuriamoci che i valori dei pixel siano compresi tra 0 e 1\n",
    "image_np = np.clip(image_np, 0, 1)\n",
    "\n",
    "# Stampa dell'immagine\n",
    "plt.imshow(image_np[0])  # Selezioniamo il primo batch (indice 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF affine_grid e PYTORCH grid_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def affine_grid(theta, size):\n",
    "    # Estraiamo la dimensione della griglia\n",
    "    _, _, height, width  = size\n",
    "\n",
    "    # Creiamo una griglia di coordinate normalizzate\n",
    "    x = tf.linspace(-1.0, 1.0, width)\n",
    "    y = tf.linspace(-1.0, 1.0, height)\n",
    "    x_t, y_t = tf.meshgrid(x, y)\n",
    "    ones = tf.ones_like(x_t)\n",
    "    grid = tf.stack([x_t, y_t, ones], axis=-1)\n",
    "\n",
    "    # Riformattiamo la griglia per poter fare una moltiplicazione batch-wise\n",
    "    grid = tf.reshape(grid, [-1, height * width, 3])\n",
    "\n",
    "    # Applichiamo la trasformazione affine\n",
    "    theta = tf.reshape(theta, [-1, 2, 3])\n",
    "    grid = tf.matmul(grid, tf.transpose(theta, [0, 2, 1]))\n",
    "\n",
    "    # Riportiamo la griglia nella sua forma originale\n",
    "    grid = tf.reshape(grid, [-1, height, width, 2])\n",
    "\n",
    "    return grid\n",
    "\n",
    "# Esempio di utilizzo\n",
    "import numpy as np\n",
    "\n",
    "# Definizione della trasformazione affine (ad esempio una rotazione di 45 gradi)\n",
    "theta = np.array([[np.cos(np.pi/3), -np.sin(np.pi/3), 0],\n",
    "                  [np.sin(np.pi/3), np.cos(np.pi/3), 0]], dtype=np.float32)\n",
    "\n",
    "# Definizione della dimensione della griglia\n",
    "size = (1, 3, 112, 112)  # Immagine 28x28\n",
    "\n",
    "# Creazione della griglia di coordinate affine\n",
    "grid = affine_grid(theta, size)\n",
    "\n",
    "# Stampa della shape dell'output\n",
    "print(grid.shape)  # Output trasformato\n",
    "\n",
    "numpy_grid_tensor = grid.numpy()  # Converti il tensore TensorFlow in NumPy array\n",
    "grid_torch = torch.from_numpy(numpy_grid_tensor)  # Converti il NumPy array in un tensore PyTorch\n",
    "\n",
    "# Esempio di utilizzo: applicare un'immagine di input alla griglia di coordinate\n",
    "input_image = torch.randn(1, 3, 112, 112)  # Immagine di input 28x28\n",
    "\n",
    "print(input_image)\n",
    "\n",
    "output_image = F.grid_sample(input_image, grid_torch)\n",
    "\n",
    "print(output_image.shape)  # Output trasformato\n",
    "\n",
    "# Spostiamo il tensore su CPU e lo convertiamo in un array numpy\n",
    "image_np = output_image.cpu().detach().numpy()\n",
    "\n",
    "# Trasformiamo l'immagine in formato CHW (canale, altezza, larghezza) in formato HWC (altezza, larghezza, canale)\n",
    "image_np = np.transpose(image_np, (0, 2, 3, 1))\n",
    "\n",
    "# Assicuriamoci che i valori dei pixel siano compresi tra 0 e 1\n",
    "image_np = np.clip(image_np, 0, 1)\n",
    "\n",
    "# Stampa dell'immagine\n",
    "plt.imshow(image_np[0])  # Selezioniamo il primo batch (indice 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def affine_grid(theta, size):\n",
    "    # Estraiamo la dimensione della griglia\n",
    "    _, _, height, width  = size\n",
    "\n",
    "    # Creiamo una griglia di coordinate normalizzate\n",
    "    x = tf.linspace(-1.0, 1.0, width)\n",
    "    y = tf.linspace(-1.0, 1.0, height)\n",
    "    x_t, y_t = tf.meshgrid(x, y)\n",
    "    ones = tf.ones_like(x_t)\n",
    "    grid = tf.stack([x_t, y_t, ones], axis=-1)\n",
    "\n",
    "    # Riformattiamo la griglia per poter fare una moltiplicazione batch-wise\n",
    "    grid = tf.reshape(grid, [-1, height * width, 3])\n",
    "\n",
    "    # Applichiamo la trasformazione affine\n",
    "    theta = tf.reshape(theta, [-1, 2, 3])\n",
    "    grid = tf.matmul(grid, tf.transpose(theta, [0, 2, 1]))\n",
    "\n",
    "    # Riportiamo la griglia nella sua forma originale\n",
    "    grid = tf.reshape(grid, [-1, height, width, 2])\n",
    "\n",
    "    return grid\n",
    "\n",
    "def grid_sample(input, grid):\n",
    "    def process_coord(grid, w_h):\n",
    "        pixs = (grid + 1) * (0.5 * w_h) - 0.5\n",
    "        pixs = tf.clip_by_value(pixs, -1, w_h) + 1\n",
    "        return pixs\n",
    "    \n",
    "    def gather(input, y, x, b, h, w, c):\n",
    "        w_padded = w + 2\n",
    "        h_padded = h + 2\n",
    "        linear_coordinates = tf.cast(y * w_padded + x, dtype=tf.int32)\n",
    "        linear_coordinates = tf.reshape(linear_coordinates, shape=(b, h, w))\n",
    "        input = tf.reshape(input, shape=(b, h_padded * w_padded, c))\n",
    "        out = tf.gather(params=input, indices=linear_coordinates, batch_dims=1)\n",
    "        return out\n",
    "\n",
    "    b, h, w, c = tf.cast(tf.shape(input), tf.float32)\n",
    "\n",
    "    grid_x, grid_y = tf.split(grid, num_or_size_splits=2, axis=-1)\n",
    "    x = process_coord(grid_x, w)\n",
    "    y = process_coord(grid_y, h)\n",
    "\n",
    "    input = tf.keras.layers.ZeroPadding2D(padding=(1, 1))(input)\n",
    "\n",
    "    x0 = tf.math.floor(x)\n",
    "    y0 = tf.math.floor(y)\n",
    "    x1 = tf.math.ceil(x)\n",
    "    y1 = tf.math.ceil(y)\n",
    "\n",
    "    dx = x - x0\n",
    "    dy = y - y0\n",
    "    oneminus_dx = 1 - dx\n",
    "    oneminus_dy = 1 - dy\n",
    "    w_y0_x0 = oneminus_dy * oneminus_dx\n",
    "    w_y1_x0 = dy * oneminus_dx\n",
    "    w_y1_x1 = dy * dx\n",
    "    w_y0_x1 = oneminus_dy * dx\n",
    "\n",
    "    v_y0_x0 = gather(input, y0, x0, b, h, w, c)\n",
    "    v_y1_x0 = gather(input, y1, x0, b, h, w, c)\n",
    "    v_y1_x1 = gather(input, y1, x1, b, h, w, c)\n",
    "    v_y0_x1 = gather(input, y0, x1, b, h, w, c)\n",
    "\n",
    "    return w_y0_x0 * v_y0_x0 + w_y1_x0 * v_y1_x0 + w_y1_x1 * v_y1_x1 + w_y0_x1 * v_y0_x1\n",
    "\n",
    "\n",
    "# Definizione della trasformazione affine (ad esempio una rotazione di 45 gradi)\n",
    "theta = np.array([[np.cos(np.pi/4), -np.sin(np.pi/4), 0],\n",
    "                  [np.sin(np.pi/4), np.cos(np.pi/4), 0]], dtype=np.float32)\n",
    "\n",
    "# Definizione della dimensione della griglia (per immagine 112x112)\n",
    "size = (1, 3, 112, 112)\n",
    "\n",
    "# Creazione della griglia di coordinate affine\n",
    "grid = affine_grid(theta, size)\n",
    "\n",
    "# immagine di input random 112x112 \n",
    "input_image = tf.constant(np.random.randn(1, 112, 112, 3).astype(np.float32))\n",
    "\n",
    "# applicazione trasformazione affine ad immagine\n",
    "output_image = grid_sample(input_image, grid)\n",
    "\n",
    "# Stampa delle immagini in una griglia orizzontale\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Stampa immagine di input\n",
    "axes[0].imshow(np.clip(input_image[0].numpy(), 0, 1))\n",
    "axes[0].set_title('Input Image')\n",
    "\n",
    "# Stampa immagine trasformata\n",
    "axes[1].imshow(np.clip(output_image[0].numpy(), 0, 1))\n",
    "axes[1].set_title('Transformed Image')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
